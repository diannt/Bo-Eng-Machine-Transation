{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toycode for PyTorch-Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far I have bumped into many technical difficulties related to Pytorch-lightning and Tensorboard. In this notebook, I will use a simple model and dataset to experiment with different functionalities including: \n",
    "\n",
    "<ul>\n",
    "    <li>Tensorboard logging</li>\n",
    "    <li>Callback</li> \n",
    "    <li>Freeze parameters</li>\n",
    "</ul>\n",
    "\n",
    "Other things I need to experiment \n",
    "\n",
    "<ul>\n",
    "    <li>Rouge metric and other metrics</li>\n",
    "    <li>Optimizer and scheduler</li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 points\n",
    "X = (np.random.rand(1000, 5) ** 2 * 5).tolist()\n",
    "# Labels are the norms of 1000 points\n",
    "y = (np.sqrt(np.sum(np.square(X), axis = 1))).tolist()\n",
    "\n",
    "X_train, y_train = X[:800], y[:800]\n",
    "X_val, y_val = X[800:], y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    def __init__(self, X, y): \n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(y)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return {\n",
    "            'source': torch.tensor(X[idx]), \n",
    "            'target': torch.tensor(y[idx])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule): \n",
    "    ''' Part 1: Define the architecture of model in init '''\n",
    "    def __init__(self, hparams):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(5, 10)\n",
    "        self.layer2 = nn.Linear(10, 8)\n",
    "        self.layer3 = nn.Linear(8, 1)\n",
    "        self.hparams = hparams \n",
    "        \n",
    "    ''' Part 2: Define the forward propagation '''\n",
    "    def forward(self, x): \n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "    ''' Part 3: Prepare optimizer and scheduler '''\n",
    "    def configure_optimizer(self): \n",
    "        optimizer = AdamW(self.parameters, lr = self.hparams['learning_rate'])\n",
    "        return optimizer\n",
    "    \n",
    "    ''' Part 4: Training logic '''\n",
    "    def training_step(self, batch, batch_idx): \n",
    "        X = batch['source']\n",
    "        y = batch['target']\n",
    "        y_hat = self(X)    # Calls forward function \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    ''' Part 5: Validation logic '''\n",
    "    def validation_step(self, batch, batch_idx): \n",
    "        X = batch['source']\n",
    "        y = batch['target']\n",
    "        y_hat = self(X)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "    ''' Part 6: Data loaders '''\n",
    "    def train_dataloader(self): \n",
    "        dataset = MyDataset(X[:800], y[:800])\n",
    "        return DataLoader(dataset, batch_size = hparams['batch_size'])\n",
    "    \n",
    "    def train_dataloader(self): \n",
    "        dataset = MyDataset(X[:800], y[:800])\n",
    "        return DataLoader(dataset, batch_size = hparams['batch_size'])\n",
    "    \n",
    "    def train_dataloader(self): \n",
    "        dataset = MyDataset(X[:800], y[:800])\n",
    "        return DataLoader(dataset, batch_size = hparams['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'learning_rate': 3e-4, \n",
    "    'batch_size': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = MyModel(hparams)\n",
    "trainer = pl.Trainer\n",
    "trainer.fit(model,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
